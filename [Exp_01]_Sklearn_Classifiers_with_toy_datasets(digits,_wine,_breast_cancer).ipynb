{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Exp-01] Sklearn Classifiers with toy datasets(digits, wine, breast cancer).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPzp526L+EJ0icD/3pLv2mW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sgr1118/sgr1118/blob/main/%5BExp_01%5D_Sklearn_Classifiers_with_toy_datasets(digits%2C_wine%2C_breast_cancer).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1-11. 프로젝트 (1) load_digits : 손글씨를 분류해 봅시다"
      ],
      "metadata": {
        "id": "wy2T7Uff7XBM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23u2GdIr7WWY",
        "outputId": "2043d455-205d-458a-ae16-696e5f73c1cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model1 0.9986 0.9694 0.0056\n",
            "model2 1.0000 0.8500 0.0139\n",
            "model2 3 0.4857 0.4278 0.0944\n",
            "model2 4 0.5832 0.5194 0.0944\n",
            "model2 5 0.6882 0.6389 0.0750\n",
            "model2 6 0.8079 0.7500 0.0694\n",
            "model2 7 0.8942 0.8167 0.0306\n",
            "model3 1.0000 0.9694 0.0111\n",
            "model3 3 0.8970 0.8778 0.0944\n",
            "model3 4 0.9388 0.9139 0.0944\n",
            "model3 5 0.9749 0.9333 0.0722\n",
            "model3 6 0.9868 0.9444 0.0500\n",
            "model3 7 0.9979 0.9472 0.0250\n",
            "model4 1.0000 0.9750 0.0056\n",
            "model5 0.9875 0.9472 0.0194\n"
          ]
        }
      ],
      "source": [
        "# (1) 필요한 모듈 import\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "pd.set_option('max_rows',500)\n",
        "pd.set_option('max_columns',30)\n",
        "\n",
        "# (2) 데이터 준비\n",
        "dataset = load_digits()\n",
        "feature = dataset.data\n",
        "labels = dataset.target\n",
        "digits_df = pd.DataFrame(data=feature, columns = dataset.feature_names)\n",
        "digits_df['target'] = labels\n",
        "\n",
        "# (3)데이터 이해하기\n",
        "# Target Names 출력해 보기\n",
        "#dataset.target_names array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "#print(digits_df['target'].value_counts()) \n",
        "\n",
        "# 데이터 Describe 해 보기\n",
        "#print(digits.DESCR)\n",
        "\n",
        "# 데이터 분해\n",
        "X = digits_df.iloc[:, :-1]\n",
        "Y = digits_df.iloc[:,-1]\n",
        "\n",
        "scalerX = StandardScaler().fit_transform(X)\n",
        "#print(scalerX.mean(), scalerX.std()) # 1.606332701182753e-18 0.9762812094883317\n",
        "\n",
        "# 함수 작성\n",
        "def get_scores(model, xtrain, xtest, ytrain, ytest):\n",
        "    A = model.score(xtrain, ytrain)\n",
        "    B = model.score(xtest, ytest)\n",
        "    ypred = model.predict_proba(xtest)[:, 1]\n",
        "    preds_1d = ypred.flatten()\n",
        "    pred_class = np.where(preds_1d > 0.5, 2 , 1)\n",
        "    C = accuracy_score(ytest, pred_class)  \n",
        "    return '{:.4f} {:.4f} {:.4f}'.format(A, B, C)\n",
        "\n",
        "def make_models(xtrain, xtest, ytrain, ytest):\n",
        "  model1 = LogisticRegression(max_iter=5000).fit(xtrain, ytrain)\n",
        "  print('model1', get_scores(model1, xtrain, xtest, ytrain, ytest))\n",
        "\n",
        "  model2 = DecisionTreeClassifier(random_state=10).fit(xtrain, ytrain)\n",
        "  print('model2', get_scores(model2, xtrain, xtest, ytrain, ytest))\n",
        "  \n",
        "  # overfitting 해결\n",
        "  for d in range(3, 8):\n",
        "      model2 = DecisionTreeClassifier(max_depth=d,random_state=10).fit(xtrain, ytrain)\n",
        "      print('model2', d, get_scores(model2, xtrain, xtest, ytrain, ytest))\n",
        "\n",
        "  model3 = RandomForestClassifier(random_state=0).fit(xtrain, ytrain)\n",
        "  print('model3', get_scores(model3, xtrain, xtest, ytrain, ytest))\n",
        "\n",
        "  # overfitting 해결\n",
        "  for d in range(3, 8):\n",
        "      model3 = RandomForestClassifier(500, max_depth=d, random_state=10).fit(xtrain, ytrain)\n",
        "      print('model3', d, get_scores(model3, xtrain, xtest, ytrain, ytest))\n",
        "\n",
        "  model4 = SVC(kernel = 'linear', C=1.0, random_state=0, probability=True).fit(xtrain, ytrain)      \n",
        "  print('model4', get_scores(model4, xtrain, xtest, ytrain, ytest))\n",
        "\n",
        "  model5 = SGDClassifier(loss='modified_huber', max_iter=500).fit(xtrain, ytrain)\n",
        "  print('model5', get_scores(model5, xtrain, xtest, ytrain, ytest))\n",
        "\n",
        "# (4) train, test 데이터 분리\n",
        "# train, test  8:2 분할, random_state=10 적용\n",
        "xtrain1, xtest1, ytrain1, ytest1 = train_test_split(scalerX, Y, \n",
        "                                                   test_size = 0.2,\n",
        "                                                   random_state=10)\n",
        "\n",
        "# 최적의 파라미터 찾기 (max_depth)\n",
        "#params = {'max_depth': range(3, 10)}\n",
        "#model = RandomForestClassifier(500, random_state=10)\n",
        "#gs = GridSearchCV(model, params, cv=5)\n",
        "#gs.fit(scalerX, Y)\n",
        "#result = pd.DataFrame(gs.cv_results_)\n",
        "#result\n",
        "#model = gs.best_estimator_\n",
        "#print(model.score(xtest1, ytest1), gs.score(xtest1, ytest1), gs.best_params_)\n",
        "\n",
        "# (5) 모델의 학습 및 예측\n",
        "make_models(xtrain1, xtest1, ytrain1, ytest1)\n",
        "\n",
        "# (6) 모델 평가\n",
        "#print(classification_report(ytest1, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1-12. 프로젝트 (2) load_wine : 와인을 분류해 봅시다"
      ],
      "metadata": {
        "id": "OKgeA7lc7bfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (1) 필요한 모듈 import\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "pd.set_option('max_rows',500)\n",
        "pd.set_option('max_columns',30)\n",
        "\n",
        "# (2) 데이터 준비\n",
        "dataset = load_wine()\n",
        "feature = dataset.data\n",
        "labels = dataset.target\n",
        "\n",
        "#dataset.target_names # array(['class_0', 'class_1', 'class_2'], dtype='<U7'\n",
        "wine_df = pd.DataFrame(data=feature, columns = dataset.feature_names)\n",
        "wine_df['target'] = labels\n",
        "\n",
        "# (3)데이터 이해하기\n",
        "#Target Names 출력해 보기\n",
        "#print(dataset.target_names) # ['class_0' : 0,  'class_1' : 1, 'class_2']\n",
        "#print(wine_df['target'].value_counts()) # 1: 71, 0: 59, 2: 48\n",
        "\n",
        "# 데이터 Describe 해 보기\n",
        "#print(wine.DESCR)\n",
        "\n",
        "# 데이터 분해\n",
        "X = wine_df.iloc[:, :-1]\n",
        "Y = wine_df.iloc[:,-1]\n",
        "\n",
        "scalerX = StandardScaler().fit_transform(X)\n",
        "#print(scalerX.mean(), scalerX.std()) # 4.66735072755122e-16 1.0\n",
        "\n",
        "# 함수 작성\n",
        "def get_scores(model, xtrain, xtest, ytrain, ytest):\n",
        "    A = model.score(xtrain, ytrain)\n",
        "    B = model.score(xtest, ytest)\n",
        "    ypred = model.predict_proba(xtest)[:, 1]\n",
        "    preds_1d = ypred.flatten()\n",
        "    pred_class = np.where(preds_1d > 0.5, 2 , 1)\n",
        "    C = accuracy_score(ytest, pred_class)  \n",
        "    return '{:.4f} {:.4f} {:.4f}'.format(A, B, C)\n",
        "\n",
        "def make_models(xtrain, xtest, ytrain, ytest):\n",
        "  model1 = LogisticRegression(max_iter=5000).fit(xtrain, ytrain)\n",
        "  print('model1', get_scores(model1, xtrain, xtest, ytrain, ytest))\n",
        "\n",
        "  model2 = DecisionTreeClassifier(random_state=10).fit(xtrain, ytrain)\n",
        "  print('model2', get_scores(model2, xtrain, xtest, ytrain, ytest))\n",
        "  \n",
        "  # overfitting 해결\n",
        "  for d in range(3, 8):\n",
        "      model2 = DecisionTreeClassifier(max_depth=d,random_state=10).fit(xtrain, ytrain)\n",
        "      print('model2', d, get_scores(model2, xtrain, xtest, ytrain, ytest))\n",
        "\n",
        "  model3 = RandomForestClassifier(random_state=0).fit(xtrain, ytrain)\n",
        "  print('model3', get_scores(model3, xtrain, xtest, ytrain, ytest))\n",
        "\n",
        "  # overfitting 해결\n",
        "  for d in range(3, 8):\n",
        "      model3 = RandomForestClassifier(500, max_depth=d, random_state=10).fit(xtrain, ytrain)\n",
        "      print('model3', d, get_scores(model3, xtrain, xtest, ytrain, ytest))\n",
        "\n",
        "  model4 = SVC(kernel = 'linear', C=1.0, random_state=0, probability=True).fit(xtrain, ytrain)      \n",
        "  print('model4', get_scores(model4, xtrain, xtest, ytrain, ytest))\n",
        "\n",
        "  model5 = SGDClassifier(loss='modified_huber', max_iter=100).fit(xtrain, ytrain)\n",
        "  print('model5', get_scores(model5, xtrain, xtest, ytrain, ytest))\n",
        "\n",
        "# (4) train, test 데이터 분리\n",
        "# train, test  8:2 분할, random_state=10 적용\n",
        "xtrain1, xtest1, ytrain1, ytest1 = train_test_split(scalerX, Y, \n",
        "                                                   test_size = 0.2,\n",
        "                                                   random_state=10)\n",
        "\n",
        "# 최적의 파라미터 찾기 (max_depth)\n",
        "#params = {'max_depth': range(3, 10)}\n",
        "#model = RandomForestClassifier(500, random_state=10)\n",
        "#gs = GridSearchCV(model, params, cv=5)\n",
        "#gs.fit(scalerX, Y)\n",
        "#result = pd.DataFrame(gs.cv_results_)\n",
        "#result\n",
        "#model = gs.best_estimator_\n",
        "#print(model.score(xtest1, ytest1), gs.score(xtest1, ytest1), gs.best_params_)\n",
        "\n",
        "# (5) 모델의 학습 및 예측\n",
        "make_models(xtrain1, xtest1, ytrain1, ytest1)\n",
        "\n",
        "# (6) 모델 평가\n",
        "#print(classification_report(ytest1, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4WCI4Bv7k0u",
        "outputId": "af36d45e-a722-483b-c13d-b794a40e6283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.66735072755122e-16 1.0\n",
            "model1 1.0000 0.9167 0.0833\n",
            "model2 1.0000 0.9444 0.0556\n",
            "model2 3 0.9859 0.9444 0.0556\n",
            "model2 4 0.9930 0.9444 0.0556\n",
            "model2 5 1.0000 0.9444 0.0556\n",
            "model2 6 1.0000 0.9444 0.0556\n",
            "model2 7 1.0000 0.9444 0.0556\n",
            "model3 1.0000 0.9444 0.0833\n",
            "model3 3 1.0000 0.9167 0.1111\n",
            "model3 4 1.0000 0.9444 0.1111\n",
            "model3 5 1.0000 0.9444 0.0833\n",
            "model3 6 1.0000 0.9444 0.0833\n",
            "model3 7 1.0000 0.9444 0.0833\n",
            "model4 1.0000 0.9167 0.0833\n",
            "model5 0.9930 0.9167 0.0833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1-13. 프로젝트 (3) load_breast_cancer : 유방암 여부를 진단해 봅시다"
      ],
      "metadata": {
        "id": "1i3M_XSj7hYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (1) 필요한 모듈 import\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "pd.set_option('max_rows',500)\n",
        "pd.set_option('max_columns',30)\n",
        "\n",
        "# (2) 데이터 준비\n",
        "dataset = load_breast_cancer()\n",
        "feature = dataset.data\n",
        "labels = dataset.target\n",
        "#breast_cancer.target_names # array(['malignant', 'benign'], dtype='<U9')\n",
        "cancer_df = pd.DataFrame(data=feature, columns = dataset.feature_names)\n",
        "cancer_df['target'] = labels\n",
        "#cancer_df.head()\n",
        "\n",
        "# (3)데이터 이해하기\n",
        "#print(dataset.target_names) # ['malignant' : 0,  'benign' : 1]\n",
        "#print(cancer_df['target'].value_counts()) 1: 357, 0: 212\n",
        "\n",
        "X = cancer_df.iloc[:, :-1]\n",
        "Y = cancer_df.iloc[:,-1]\n",
        "\n",
        "scalerX = StandardScaler().fit_transform(X)\n",
        "#print(scalerX.mean(), scalerX.std()) # -6.118909323768877e-16 1.0\n",
        "\n",
        "# 함수 작성\n",
        "def get_scores(model, xtrain, xtest, ytrain, ytest):\n",
        "    A = model.score(xtrain, ytrain)\n",
        "    B = model.score(xtest, ytest)\n",
        "    ypred = model.predict_proba(xtest)[:, 1]\n",
        "    C = roc_auc_score(ytest, ypred)  \n",
        "    return '{:.4f} {:.4f} {:.4f}'.format(A, B, C)\n",
        "\n",
        "def make_models(xtrain, xtest, ytrain, ytest):\n",
        "  model1 = LogisticRegression(max_iter=5000).fit(xtrain, ytrain)\n",
        "  print('model1', get_scores(model1, xtrain, xtest, ytrain, ytest))\n",
        "\n",
        "  model2 = DecisionTreeClassifier(random_state=10).fit(xtrain, ytrain)\n",
        "  print('model2', get_scores(model2, xtrain, xtest, ytrain, ytest))\n",
        "  \n",
        "  # overfitting 해결\n",
        "  for d in range(3, 8):\n",
        "      model2 = DecisionTreeClassifier(max_depth=d,random_state=10).fit(xtrain, ytrain)\n",
        "      print('model2', d, get_scores(model2, xtrain, xtest, ytrain, ytest))\n",
        "\n",
        "  model3 = RandomForestClassifier(random_state=0).fit(xtrain, ytrain)\n",
        "  print('model3', get_scores(model3, xtrain, xtest, ytrain, ytest))\n",
        "\n",
        "  # overfitting 해결\n",
        "  for d in range(3, 8):\n",
        "      model3 = RandomForestClassifier(500, max_depth=d, random_state=10).fit(xtrain, ytrain)\n",
        "      print('model3', d, get_scores(model3, xtrain, xtest, ytrain, ytest))\n",
        "\n",
        "  model4 = SVC(kernel = 'linear', C=1.0, random_state=0, probability=True).fit(xtrain, ytrain)      \n",
        "  print('model4', get_scores(model4, xtrain, xtest, ytrain, ytest))\n",
        "\n",
        "  model5 = SGDClassifier(loss='modified_huber', max_iter=100).fit(xtrain, ytrain)\n",
        "  print('model5', get_scores(model5, xtrain, xtest, ytrain, ytest))\n",
        "\n",
        "# train, test  8:2 분할, random_state=10 적용\n",
        "xtrain1, xtest1, ytrain1, ytest1 = train_test_split(scalerX, Y, \n",
        "                                                   test_size = 0.2,\n",
        "                                                   random_state=10)\n",
        "\n",
        "# 최적의 파라미터 찾기 (max_depth)\n",
        "#params = {'max_depth': range(3, 10)}\n",
        "#model = RandomForestClassifier(500, random_state=10)\n",
        "#gs = GridSearchCV(model, params, cv=5)\n",
        "#gs.fit(scalerX, Y)\n",
        "#result = pd.DataFrame(gs.cv_results_)\n",
        "#result\n",
        "#model = gs.best_estimator_\n",
        "#print(model.score(xtest1, ytest1), gs.score(xtest1, ytest1), gs.best_params_)\n",
        "\n",
        "# (5) 모델의 학습 및 예측\n",
        "make_models(xtrain1, xtest1, ytrain1, ytest1)\n",
        "\n",
        "# (6) 모델 평가\n",
        "#print(classification_report(ytest1, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "iUIZjX8q7lWJ",
        "outputId": "2afed649-4915-4546-a1d9-c0303a8d16ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-db88d5319139>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mbreast_cancer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_names\u001b[0m \u001b[0;31m# array(['malignant', 'benign'], dtype='<U9')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mcancer_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mcancer_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'breast_cancer' is not defined"
          ]
        }
      ]
    }
  ]
}